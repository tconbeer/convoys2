<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>convoys.regression &#8212; Convoys  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=27fed22d" />
    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for convoys.regression</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Literal</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">autograd</span>  <span class="c1"># type: ignore[import-untyped]</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">emcee</span>  <span class="c1"># type: ignore[import-untyped]</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">progressbar</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.optimize</span>  <span class="c1"># type: ignore[import-untyped]</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">autograd.numpy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># type: ignore[import-untyped]</span>
    <span class="n">dot</span><span class="p">,</span>
    <span class="n">exp</span><span class="p">,</span>
    <span class="n">isnan</span><span class="p">,</span>
    <span class="n">log</span><span class="p">,</span>
    <span class="nb">sum</span><span class="p">,</span>  <span class="c1"># noqa: A004</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">autograd.scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">expit</span><span class="p">,</span> <span class="n">gammaln</span>  <span class="c1"># type: ignore[import-untyped]</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">autograd_gamma</span><span class="w"> </span><span class="kn">import</span> <span class="n">gammainc</span>  <span class="c1"># type: ignore[import-untyped]</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">gammaincinv</span>  <span class="c1"># type: ignore[import-untyped]</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArrayLike</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Exponential&quot;</span><span class="p">,</span> <span class="s2">&quot;Weibull&quot;</span><span class="p">,</span> <span class="s2">&quot;Gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;GeneralizedGamma&quot;</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">generalized_gamma_loss</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">B</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">T</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">fix_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fix_p</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hierarchical</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">flavor</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;logistic&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span>
    <span class="n">callback</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">fix_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">fix_k</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="n">fix_p</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">fix_p</span>
    <span class="n">log_sigma_alpha</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">log_sigma_beta</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">6</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span> <span class="p">:</span> <span class="mi">6</span> <span class="o">+</span> <span class="n">n_features</span><span class="p">]</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span> <span class="o">+</span> <span class="n">n_features</span> <span class="p">:</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">]</span>
    <span class="n">lambd</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span>

    <span class="c1"># PDF: p*lambda^(k*p) / gamma(k) * t^(k*p-1) * exp(-(x*lambda)^p)</span>
    <span class="n">log_pdf</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="o">+</span> <span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">lambd</span><span class="p">)</span>
        <span class="o">-</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="o">+</span> <span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
        <span class="o">-</span> <span class="p">(</span><span class="n">T</span> <span class="o">*</span> <span class="n">lambd</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span>
    <span class="p">)</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">gammainc</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">T</span> <span class="o">*</span> <span class="n">lambd</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">flavor</span> <span class="o">==</span> <span class="s2">&quot;logistic&quot;</span><span class="p">:</span>  <span class="c1"># Log-likelihood with sigmoid</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">LL_observed</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_pdf</span>
        <span class="n">LL_censored</span> <span class="o">=</span> <span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cdf</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">flavor</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>  <span class="c1"># L2 loss, linear</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">LL_observed</span> <span class="o">=</span> <span class="o">-</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_pdf</span>
        <span class="n">LL_censored</span> <span class="o">=</span> <span class="o">-</span><span class="p">((</span><span class="n">c</span> <span class="o">*</span> <span class="n">cdf</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">LL_data</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">B</span> <span class="o">*</span> <span class="n">LL_observed</span> <span class="o">+</span> <span class="n">W</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">B</span><span class="p">)</span> <span class="o">*</span> <span class="n">LL_censored</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">hierarchical</span><span class="p">:</span>
        <span class="c1"># Hierarchical model with sigmas ~ invgamma(1, 1)</span>
        <span class="n">LL_prior_a</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mi">4</span> <span class="o">*</span> <span class="n">log_sigma_alpha</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_alpha</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="n">dot</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_alpha</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">n_features</span> <span class="o">*</span> <span class="n">log_sigma_alpha</span>
        <span class="p">)</span>
        <span class="n">LL_prior_b</span> <span class="o">=</span> <span class="p">(</span>
            <span class="o">-</span><span class="mi">4</span> <span class="o">*</span> <span class="n">log_sigma_beta</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_beta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_beta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">n_features</span> <span class="o">*</span> <span class="n">log_sigma_beta</span>
        <span class="p">)</span>
        <span class="n">LL</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">LL_prior_a</span> <span class="o">+</span> <span class="n">LL_prior_b</span> <span class="o">+</span> <span class="n">LL_data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">LL</span> <span class="o">=</span> <span class="n">LL_data</span>

    <span class="k">if</span> <span class="n">isnan</span><span class="p">(</span><span class="n">LL</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">callback</span><span class="p">(</span><span class="n">LL</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">LL</span>


<span class="k">class</span><span class="w"> </span><span class="nc">RegressionModel</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">B</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">W</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Need to implement fit&quot;</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">group</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Need to implement predict&quot;</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_ci</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">group</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">ci</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Need to implement predict_ci&quot;</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rvs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Need to implement rvs&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="GeneralizedGamma">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GeneralizedGamma</span><span class="p">(</span><span class="n">RegressionModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generalization of Gamma, Weibull, and Exponential</span>

<span class="sd">    :param mcmc: boolean, defaults to False. Whether to use MCMC to</span>
<span class="sd">        sample from the posterior so that a confidence interval can be</span>
<span class="sd">        estimated later (see :meth:`predict`).</span>
<span class="sd">    :param hierarchical: boolean denoting whether we have a (Normal) prior</span>
<span class="sd">        on the alpha and beta parameters to regularize. The variance of</span>
<span class="sd">        the normal distribution is in itself assumed to be an inverse</span>
<span class="sd">        gamma distribution (1, 1).</span>
<span class="sd">    :param flavor: defaults to logistic. If set to &#39;linear&#39;, then an</span>
<span class="sd">        linear model is fit, where the beta params will be completely</span>
<span class="sd">        additive. This creates a much more interpretable model, with some</span>
<span class="sd">        minor loss of accuracy.</span>

<span class="sd">    This mostly follows the `Wikipedia article</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Generalized_gamma_distribution&gt;`_, although</span>
<span class="sd">    our notation is slightly different. Also see `this paper</span>
<span class="sd">    &lt;http://data.princeton.edu/pop509/ParametricSurvival.pdf&gt;`_ for an overview.</span>

<span class="sd">    **Shape of the probability function**</span>

<span class="sd">    The cumulative density function is:</span>

<span class="sd">    :math:`F(t) = P(k, (t\\lambda)^p)`</span>

<span class="sd">    where :math:`P(a, x) = \\gamma(a, x) / \\Gamma(a)` is the lower regularized</span>
<span class="sd">    incomplete gamma function.</span>
<span class="sd">    :math:`\\gamma(a, x)` is the incomplete gamma function and :math:`\\Gamma(a)`</span>
<span class="sd">    is the standard gamma function.</span>

<span class="sd">    The probability density function is:</span>

<span class="sd">    :math:`f(t) = p\\lambda^{kp} t^{kp-1} \\exp(-(t\\lambda)^p) / \\Gamma(k)`</span>

<span class="sd">    **Modeling conversion rate**</span>

<span class="sd">    Since our goal is to model the conversion rate, we assume the conversion</span>
<span class="sd">    rate converges to a final value</span>

<span class="sd">    :math:`c = \\sigma(\\mathbf{\\beta^Tx} + b)`</span>

<span class="sd">    where :math:`\\sigma(z) = 1/(1+e^{-z})` is the sigmoid function,</span>
<span class="sd">    :math:`\\mathbf{\\beta}` is an unknown vector we are solving for (with</span>
<span class="sd">    corresponding  intercept :math:`b`), and :math:`\\mathbf{x}` are the</span>
<span class="sd">    feature vector (inputs).</span>

<span class="sd">    We also assume that the rate parameter :math:`\\lambda` is determined by</span>

<span class="sd">    :math:`\\lambda = exp(\\mathbf{\\alpha^Tx} + a)`</span>

<span class="sd">    where :math:`\\mathrm{\\alpha}` is another unknown vector we are</span>
<span class="sd">    trying to solve for (with corresponding intercept :math:`a`).</span>

<span class="sd">    We also assume that the :math:`\\mathbf{\\alpha}, \\mathbf{\\beta}`</span>
<span class="sd">    vectors have a normal distribution</span>

<span class="sd">    :math:`\\alpha_i \\sim \\mathcal{N}(0, \\sigma_{\\alpha})`,</span>
<span class="sd">    :math:`\\beta_i \\sim \\mathcal{N}(0, \\sigma_{\\beta})`</span>

<span class="sd">    where hyperparameters :math:`\\sigma_{\\alpha}^2, \\sigma_{\\beta}^2`</span>
<span class="sd">    are drawn from an inverse gamma distribution</span>

<span class="sd">    :math:`\\sigma_{\\alpha}^2 \\sim \\text{inv-gamma}(1, 1)`,</span>
<span class="sd">    :math:`\\sigma_{\\beta}^2 \\sim \\text{inv-gamma}(1, 1)`</span>

<span class="sd">    **List of parameters**</span>

<span class="sd">    The full model fits vectors :math:`\\mathbf{\\alpha, \\beta}` and scalars</span>
<span class="sd">    :math:`a, b, k, p, \\sigma_{\\alpha}, \\sigma_{\\beta}`.</span>

<span class="sd">    **Likelihood and censorship**</span>

<span class="sd">    For entries that convert, the contribution to the likelihood is simply</span>
<span class="sd">    the probability density given by the probability distribution function</span>
<span class="sd">    :math:`f(t)` times the final conversion rate :math:`c`.</span>

<span class="sd">    For entries that *did not* convert, there is two options. Either the</span>
<span class="sd">    entry will never convert, which has probability :math:`1-c`. Or,</span>
<span class="sd">    it will convert at some later point that we have not observed yet,</span>
<span class="sd">    with probability given by the cumulative density function</span>
<span class="sd">    :math:`F(t)`.</span>

<span class="sd">    **Solving the optimization problem**</span>

<span class="sd">    To find the MAP (max a posteriori), `scipy.optimize.minimize</span>
<span class="sd">    &lt;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize&gt;`_</span>
<span class="sd">    with the SLSQP method.</span>

<span class="sd">    If `mcmc == True`, then `emcee &lt;http://dfm.io/emcee/current/&gt;`_ is used</span>
<span class="sd">    to sample from the full posterior in order to generate uncertainty</span>
<span class="sd">    estimates for all parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mcmc</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fix_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fix_p</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hierarchical</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">flavor</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;logistic&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;logistic&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mcmc</span> <span class="o">=</span> <span class="n">mcmc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span> <span class="o">=</span> <span class="n">fix_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span> <span class="o">=</span> <span class="n">fix_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hierarchical</span> <span class="o">=</span> <span class="n">hierarchical</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_flavor</span> <span class="o">=</span> <span class="n">flavor</span>

<div class="viewcode-block" id="GeneralizedGamma.fit">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">B</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">W</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fits the model.</span>

<span class="sd">        :param X: numpy matrix of shape :math:`k \\cdot n`</span>
<span class="sd">        :param B: numpy vector of shape :math:`n`</span>
<span class="sd">        :param T: numpy vector of shape :math:`n`</span>
<span class="sd">        :param W: (optional) numpy vector of shape :math:`n`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>  <span class="c1"># type: ignore[arg-type]</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Z</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="k">for</span> <span class="n">Z</span> <span class="ow">in</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">keep_indexes</span> <span class="o">=</span> <span class="p">(</span><span class="n">T</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">B</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">B</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">W</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">keep_indexes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">n_removed</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">keep_indexes</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Warning! Removed </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> entries from inputs where &quot;</span>
                <span class="s2">&quot;T &lt;= 0 or B not 0/1 or W &lt; 0&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_removed</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">keep_indexes</span><span class="p">]</span> <span class="k">for</span> <span class="n">Z</span> <span class="ow">in</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># scipy.optimize and emcee forces the the parameters to be a vector:</span>
        <span class="c1"># (log k, log p, log sigma_alpha, log sigma_beta,</span>
        <span class="c1">#  a, b, alpha_1...alpha_k, beta_1...beta_k)</span>
        <span class="c1"># Generalized Gamma is a bit sensitive to the starting point!</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">6</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">)</span>
        <span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">)</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hierarchical</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flavor</span><span class="p">)</span>

        <span class="c1"># Set up progressbar and callback</span>
        <span class="n">bar</span> <span class="o">=</span> <span class="n">progressbar</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span>
            <span class="n">widgets</span><span class="o">=</span><span class="p">[</span>
                <span class="n">progressbar</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">9</span><span class="p">),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                <span class="s2">&quot; &quot;</span><span class="p">,</span>
                <span class="n">progressbar</span><span class="o">.</span><span class="n">BouncingBar</span><span class="p">(),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                <span class="s2">&quot; &quot;</span><span class="p">,</span>
                <span class="n">progressbar</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">6</span><span class="p">),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                <span class="s2">&quot; [&quot;</span><span class="p">,</span>
                <span class="n">progressbar</span><span class="o">.</span><span class="n">Timer</span><span class="p">(),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                <span class="s2">&quot;]&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">value_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">callback</span><span class="p">(</span><span class="n">LL</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">value_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">LL</span><span class="p">)</span>
            <span class="n">bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">value_history</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="n">LL</span><span class="p">)</span>

        <span class="c1"># Define objective and use automatic differentiation</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">generalized_gamma_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>

        <span class="n">jac</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">generalized_gamma_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">))</span>

        <span class="c1"># Find the maximum a posteriori of the distribution</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
            <span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;SLSQP&quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">9999</span><span class="p">}</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">res</span><span class="o">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Optimization failed with message: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">res</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;map&quot;</span><span class="p">:</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">}</span>

        <span class="c1"># TODO: should not use fixed k/p as search parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">)</span>

        <span class="c1"># Make sure we&#39;re in a local minimum</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">jac</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">])</span>
        <span class="n">gradient_norm</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">gradient</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gradient_norm</span> <span class="o">&gt;=</span> <span class="mf">1e-2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Might not have found a local minimum! &quot;</span>
                <span class="s2">&quot;Norm of gradient is </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gradient_norm</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Let&#39;s sample from the posterior to compute uncertainties</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mcmc</span><span class="p">:</span>
            <span class="p">(</span><span class="n">dim</span><span class="p">,)</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">n_walkers</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">dim</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">emcee</span><span class="o">.</span><span class="n">EnsembleSampler</span><span class="p">(</span>
                <span class="n">nwalkers</span><span class="o">=</span><span class="n">n_walkers</span><span class="p">,</span>
                <span class="n">ndim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                <span class="n">log_prob_fn</span><span class="o">=</span><span class="n">generalized_gamma_loss</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mcmc_initial_noise</span> <span class="o">=</span> <span class="mf">1e-3</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">result</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">mcmc_initial_noise</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_walkers</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">n_burnin</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="n">n_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mf">2000.0</span> <span class="o">/</span> <span class="n">n_walkers</span><span class="p">))</span>
            <span class="n">n_iterations</span> <span class="o">=</span> <span class="n">n_burnin</span> <span class="o">+</span> <span class="n">n_steps</span>

            <span class="n">bar</span> <span class="o">=</span> <span class="n">progressbar</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">(</span>
                <span class="n">max_value</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
                <span class="n">widgets</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">progressbar</span><span class="o">.</span><span class="n">Percentage</span><span class="p">(),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                    <span class="s2">&quot; &quot;</span><span class="p">,</span>
                    <span class="n">progressbar</span><span class="o">.</span><span class="n">Bar</span><span class="p">(),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                    <span class="s2">&quot; </span><span class="si">%d</span><span class="s2"> walkers [&quot;</span> <span class="o">%</span> <span class="n">n_walkers</span><span class="p">,</span>
                    <span class="n">progressbar</span><span class="o">.</span><span class="n">AdaptiveETA</span><span class="p">(),</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
                    <span class="s2">&quot;]&quot;</span><span class="p">,</span>
                <span class="p">],</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">)):</span>
                <span class="n">bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">result</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span> <span class="n">n_burnin</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">:</span>
                <span class="n">result</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_k</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">:</span>
                <span class="n">result</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fix_p</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="n">exp</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="n">exp</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
                <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="mi">6</span> <span class="p">:</span> <span class="mi">6</span> <span class="o">+</span> <span class="n">n_features</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="mi">6</span> <span class="o">+</span> <span class="n">n_features</span> <span class="p">:</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">lambd</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flavor</span> <span class="o">==</span> <span class="s2">&quot;logistic&quot;</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flavor</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">gammainc</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;k&quot;</span><span class="p">],</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">lambd</span><span class="p">)</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">M</span>  <span class="c1"># type: ignore[no-any-return]</span>

<div class="viewcode-block" id="GeneralizedGamma.predict_posteriori">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma.predict_posteriori">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_posteriori</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the trace samples generated via the MCMC steps.</span>

<span class="sd">        Requires the model to be fit with `mcmc == True`.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mcmc</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span></div>


<div class="viewcode-block" id="GeneralizedGamma.predict_ci">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma.predict_ci">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_ci</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">ci</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Works like :meth:`predict` but produces a confidence interval.</span>

<span class="sd">        Requires the model to be fit with `ci = True`. The return value</span>
<span class="sd">        will contain one more dimension than for :meth:`predict`, and</span>
<span class="sd">        the last dimension will have size 3, containing the mean, the</span>
<span class="sd">        lower bound of the confidence interval, and the upper bound of</span>
<span class="sd">        the confidence interval.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_posteriori</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_lo</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ci</span><span class="p">)</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_hi</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">ci</span><span class="p">)</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">y</span><span class="p">,</span> <span class="n">y_lo</span><span class="p">,</span> <span class="n">y_hi</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="GeneralizedGamma.predict">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma.predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the value of the cumulative distribution function</span>
<span class="sd">        for a fitted model (using the maximum a posteriori estimate).</span>

<span class="sd">        :param x: feature vector (or matrix)</span>
<span class="sd">        :param t: time</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span></div>


<div class="viewcode-block" id="GeneralizedGamma.rvs">
<a class="viewcode-back" href="../../index.html#convoys.regression.GeneralizedGamma.rvs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">rvs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;ArrayLike&quot;</span><span class="p">,</span>
        <span class="n">n_curves</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Samples values from this distribution</span>

<span class="sd">        T is optional and means we already observed non-conversion until T</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mcmc</span>  <span class="c1"># Need to be fit with MCMC</span>
        <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_curves</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_curves</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_curves</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_curves</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;k&quot;</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="n">n_curves</span><span class="p">)):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;k&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;p&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
            <span class="n">lambd</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>
            <span class="n">cdf_now</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">gammainc</span><span class="p">(</span>
                <span class="n">k</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">lambd</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span>
            <span class="p">)</span>  <span class="c1"># why is this outer?</span>
            <span class="n">adjusted_z</span> <span class="o">=</span> <span class="n">cdf_now</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cdf_now</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span>
            <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjusted_z</span> <span class="o">&lt;</span> <span class="n">c</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">adjusted_z</span> <span class="o">/</span> <span class="n">c</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">gammaincinv</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># x = (t * lambd)**p</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">lambd</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">~</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span></div>
</div>



<div class="viewcode-block" id="Exponential">
<a class="viewcode-back" href="../../index.html#convoys.regression.Exponential">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Exponential</span><span class="p">(</span><span class="n">GeneralizedGamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Specialization of :class:`.GeneralizedGamma` where :math:`k=1, p=1`.</span>

<span class="sd">    The cumulative density function is:</span>

<span class="sd">    :math:`F(t) = 1 - \\exp(-t\\lambda)`</span>

<span class="sd">    The probability density function is:</span>

<span class="sd">    :math:`f(t) = \\lambda\\exp(-t\\lambda)`</span>

<span class="sd">    The exponential distribution is the most simple distribution.</span>
<span class="sd">    From a conversion perspective, you can interpret it as having</span>
<span class="sd">    two competing final states where the probability of transitioning</span>
<span class="sd">    from the initial state to converted or dead is constant.</span>

<span class="sd">    See documentation for :class:`GeneralizedGamma`.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">fix_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fix_p</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Exponential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>



<div class="viewcode-block" id="Weibull">
<a class="viewcode-back" href="../../index.html#convoys.regression.Weibull">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Weibull</span><span class="p">(</span><span class="n">GeneralizedGamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Specialization of :class:`.GeneralizedGamma` where :math:`k=1`.</span>

<span class="sd">    The cumulative density function is:</span>

<span class="sd">    :math:`F(t) = 1 - \\exp(-(t\\lambda)^p)`</span>

<span class="sd">    The probability density function is:</span>

<span class="sd">    :math:`f(t) = p\\lambda(t\\lambda)^{p-1}\\exp(-(t\\lambda)^p)`</span>

<span class="sd">    See documentation for :class:`GeneralizedGamma`.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">fix_k</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Weibull</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>



<div class="viewcode-block" id="Gamma">
<a class="viewcode-back" href="../../index.html#convoys.regression.Gamma">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Gamma</span><span class="p">(</span><span class="n">GeneralizedGamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Specialization of :class:`.GeneralizedGamma` where :math:`p=1`.</span>

<span class="sd">    The cumulative density function is:</span>

<span class="sd">    :math:`F(t) = P(k, t\\lambda)`</span>

<span class="sd">    where :math:`P(a, x) = \\gamma(a, x) / \\Gamma(a)` is the lower regularized</span>
<span class="sd">    incomplete gamma function.</span>

<span class="sd">    The probability density function is:</span>

<span class="sd">    :math:`f(t) = \\lambda^k t^{k-1} \\exp(-x\\lambda) / \\Gamma(k)`</span>

<span class="sd">    See documentation for :class:`GeneralizedGamma`.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">fix_p</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Convoys</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=better&repo=convoys&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a class="badge" href="https://travis-ci.org/better/convoys">
    <img
        alt="https://secure.travis-ci.org/better/convoys.svg?branch=master"
        src="https://secure.travis-ci.org/better/convoys.svg?branch=master"
    />
</a>
</p>



<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2018, Erik Bernhardsson.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
    <script>

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-64912988-4']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>